{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Documents\\\\E_Plus_2030_py\\\\output\\\\assigned\\\\assigned_hvac_params.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 146\u001b[0m\n\u001b[0;32m    139\u001b[0m     flatten_hvac_data(\n\u001b[0;32m    140\u001b[0m         df_input\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m    141\u001b[0m         out_build_csv\u001b[38;5;241m=\u001b[39mcsv_build_out,\n\u001b[0;32m    142\u001b[0m         out_zone_csv\u001b[38;5;241m=\u001b[39mcsv_zone_out\n\u001b[0;32m    143\u001b[0m     )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 133\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    130\u001b[0m csv_zone_out  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mE_Plus_2030_py\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124massigned\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124massigned_hvac_zones.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# 3) Load CSV\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# 4) Parse the assigned_value from string to python object\u001b[39;00m\n\u001b[0;32m    136\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massigned_value\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massigned_value\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(parse_assigned_value)\n",
      "File \u001b[1;32md:\\New folder (2)\\Anaconda\\DDsaie\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\New folder (2)\\Anaconda\\DDsaie\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\New folder (2)\\Anaconda\\DDsaie\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\New folder (2)\\Anaconda\\DDsaie\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\New folder (2)\\Anaconda\\DDsaie\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Documents\\\\E_Plus_2030_py\\\\output\\\\assigned\\\\assigned_hvac_params.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def parse_assigned_value(value_str):\n",
    "    \"\"\"\n",
    "    Safely convert the string in 'assigned_value' into a Python object.\n",
    "    If it fails, return the original string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ast.literal_eval(value_str)\n",
    "    except:\n",
    "        return value_str\n",
    "\n",
    "def parse_range_tuple(val):\n",
    "    \"\"\"\n",
    "    If val is a 2-item tuple of floats, return (float1, float2).\n",
    "    Otherwise return (None, None).\n",
    "    \"\"\"\n",
    "    if isinstance(val, tuple) and len(val) == 2:\n",
    "        try:\n",
    "            return float(val[0]), float(val[1])\n",
    "        except:\n",
    "            return None, None\n",
    "    return None, None\n",
    "\n",
    "def flatten_hvac_data(df_input, out_build_csv, out_zone_csv):\n",
    "    \"\"\"\n",
    "    Splits data into:\n",
    "      1) building-level => param_name == \"hvac_params\"\n",
    "         => each key => row\n",
    "           If the value is a tuple => store param_value=\"range(x,y)\",\n",
    "                                     param_min=x, param_max=y\n",
    "           Else => store param_value as is, param_min, param_max blank\n",
    "      2) zone-level => param_name == \"zones\"\n",
    "         => flatten zone data => (bldg_id, zone_name, param_name, param_value)\n",
    "\n",
    "    Writes two CSVs.\n",
    "    \"\"\"\n",
    "    building_rows = []\n",
    "    zone_rows = []\n",
    "\n",
    "    for idx, row in df_input.iterrows():\n",
    "        bldg_id = row[\"ogc_fid\"]\n",
    "        main_pname = row[\"param_name\"]   # \"hvac_params\" or \"zones\"\n",
    "        assigned_val = row[\"assigned_value\"]\n",
    "\n",
    "        if main_pname == \"hvac_params\":\n",
    "            # assigned_val is typically a dict of e.g. {\"heating_day_setpoint\": 20.3, \"heating_day_setpoint_range\":(19,21), ...}\n",
    "            if isinstance(assigned_val, dict):\n",
    "                for k, v in assigned_val.items():\n",
    "                    param_value_str = v\n",
    "                    param_min, param_max = None, None\n",
    "\n",
    "                    # if v is a tuple => treat as range\n",
    "                    if isinstance(v, tuple) and len(v) == 2:\n",
    "                        parsed_min, parsed_max = parse_range_tuple(v)\n",
    "                        if parsed_min is not None and parsed_max is not None:\n",
    "                            param_value_str = f\"range({parsed_min},{parsed_max})\"\n",
    "                            param_min, param_max = parsed_min, parsed_max\n",
    "\n",
    "                    building_rows.append({\n",
    "                        \"ogc_fid\": bldg_id,\n",
    "                        \"param_name\": k,\n",
    "                        \"param_value\": param_value_str,\n",
    "                        \"param_min\": param_min,\n",
    "                        \"param_max\": param_max\n",
    "                    })\n",
    "            else:\n",
    "                # Unusual case if assigned_val is not a dict\n",
    "                building_rows.append({\n",
    "                    \"ogc_fid\": bldg_id,\n",
    "                    \"param_name\": \"unrecognized_hvac_params\",\n",
    "                    \"param_value\": assigned_val,\n",
    "                    \"param_min\": None,\n",
    "                    \"param_max\": None\n",
    "                })\n",
    "\n",
    "        elif main_pname == \"zones\":\n",
    "            # assigned_val => dict of zone_name => { param_name => param_value, ... }\n",
    "            if isinstance(assigned_val, dict):\n",
    "                for zone_name, zone_dict in assigned_val.items():\n",
    "                    for zparam_name, zparam_val in zone_dict.items():\n",
    "                        zone_rows.append({\n",
    "                            \"ogc_fid\": bldg_id,\n",
    "                            \"zone_name\": zone_name,\n",
    "                            \"param_name\": zparam_name,\n",
    "                            \"param_value\": zparam_val\n",
    "                        })\n",
    "            else:\n",
    "                # If it's not a dict => store raw\n",
    "                zone_rows.append({\n",
    "                    \"ogc_fid\": bldg_id,\n",
    "                    \"zone_name\": \"unrecognized_zone\",\n",
    "                    \"param_name\": \"unrecognized_zparam\",\n",
    "                    \"param_value\": assigned_val\n",
    "                })\n",
    "\n",
    "        else:\n",
    "            # If there's any other param_name, skip or store as you see fit\n",
    "            pass\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_build = pd.DataFrame(building_rows)\n",
    "    df_zone = pd.DataFrame(zone_rows)\n",
    "\n",
    "    # Ensure columns exist if empty\n",
    "    if df_build.empty:\n",
    "        df_build = pd.DataFrame(columns=[\"ogc_fid\", \"param_name\", \"param_value\", \"param_min\", \"param_max\"])\n",
    "    if df_zone.empty:\n",
    "        df_zone = pd.DataFrame(columns=[\"ogc_fid\", \"zone_name\", \"param_name\", \"param_value\"])\n",
    "\n",
    "    # Reorder columns for building-level\n",
    "    df_build = df_build[[\"ogc_fid\", \"param_name\", \"param_value\", \"param_min\", \"param_max\"]]\n",
    "    # zone-level is fine\n",
    "    df_zone = df_zone[[\"ogc_fid\", \"zone_name\", \"param_name\", \"param_value\"]]\n",
    "\n",
    "    # Write to CSV\n",
    "    df_build.to_csv(out_build_csv, index=False)\n",
    "    df_zone.to_csv(out_zone_csv, index=False)\n",
    "\n",
    "    print(f\"[INFO] Wrote building-level picks to {out_build_csv}\")\n",
    "    print(f\"[INFO] Wrote zone-level picks to {out_zone_csv}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1) Path to your original HVAC CSV\n",
    "    csv_in = r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_hvac_params.csv\"\n",
    "    # 2) Output CSVs\n",
    "    csv_build_out = r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_hvac_building.csv\"\n",
    "    csv_zone_out  = r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_hvac_zones.csv\"\n",
    "\n",
    "    # 3) Load CSV\n",
    "    df = pd.read_csv(csv_in)\n",
    "\n",
    "    # 4) Parse the assigned_value from string to python object\n",
    "    df[\"assigned_value\"] = df[\"assigned_value\"].apply(parse_assigned_value)\n",
    "\n",
    "    # 5) Flatten + export\n",
    "    flatten_hvac_data(\n",
    "        df_input=df,\n",
    "        out_build_csv=csv_build_out,\n",
    "        out_zone_csv=csv_zone_out\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[transform_fenez_log_to_structured_with_ranges] => wrote: output/assigned/structured_fenez_params.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # For safely parsing \"(4.0, 5.0)\" as a Python tuple\n",
    "\n",
    "def transform_fenez_log_to_structured_with_ranges(\n",
    "    csv_input=\"output/assigned/assigned_fenez_params.csv\",\n",
    "    csv_output=\"output/assigned/structured_fenez_params.csv\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads the 'flat' fenestration/material CSV (with param_name & assigned_value),\n",
    "    and outputs a 'structured' CSV that:\n",
    "\n",
    "      - Merges final assigned value + min/max range into one row per parameter.\n",
    "      - Does NOT skip params that have empty or None values.\n",
    "      - Always includes a row for any param that appears in the CSV, even if\n",
    "        there's no final value or no range.\n",
    "\n",
    "    Final columns:\n",
    "      ogc_fid, sub_key, eplus_object_type, eplus_object_name,\n",
    "      param_name, param_value, param_min, param_max\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(csv_input)\n",
    "\n",
    "    # We'll keep track of data in a nested dict:\n",
    "    # final_dict[(ogc_fid, sub_key)] = {\n",
    "    #   \"obj_type\": <str or None>,\n",
    "    #   \"obj_name\": <str or None>,\n",
    "    #   \"params\": {\n",
    "    #       \"Thickness\": {\n",
    "    #          \"value\": <final assigned value or None>,\n",
    "    #          \"min\": <float or None>,\n",
    "    #          \"max\": <float or None>\n",
    "    #       },\n",
    "    #       \"Conductivity\": {...},\n",
    "    #       etc.\n",
    "    #   }\n",
    "    # }\n",
    "\n",
    "    final_dict = {}\n",
    "\n",
    "    def get_subdict(fid, s_key):\n",
    "        \"\"\"Helper to retrieve or create the dictionary entry for (fid, s_key).\"\"\"\n",
    "        if (fid, s_key) not in final_dict:\n",
    "            final_dict[(fid, s_key)] = {\n",
    "                \"obj_type\": None,\n",
    "                \"obj_name\": None,\n",
    "                \"params\": {}\n",
    "            }\n",
    "        return final_dict[(fid, s_key)]\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        # Must have these columns to proceed\n",
    "        if \"ogc_fid\" not in row or \"param_name\" not in row or \"assigned_value\" not in row:\n",
    "            continue\n",
    "\n",
    "        ogc_fid = row[\"ogc_fid\"]\n",
    "        param_name = str(row[\"param_name\"])\n",
    "        assigned_value = row[\"assigned_value\"]\n",
    "\n",
    "        # We only transform if param_name starts with \"fenez_\"\n",
    "        # (Otherwise, skip non-fenestration logs.)\n",
    "        if not param_name.startswith(\"fenez_\"):\n",
    "            continue\n",
    "\n",
    "        # Remove the \"fenez_\" prefix => e.g. \"doors_opq.Thermal_Resistance_range\"\n",
    "        remainder = param_name[len(\"fenez_\"):]  # e.g. \"doors_opq.Thermal_Resistance_range\"\n",
    "\n",
    "        if \".\" in remainder:\n",
    "            sub_key, field = remainder.split(\".\", 1)\n",
    "        else:\n",
    "            # e.g. \"wwr\", \"roughness\" => treat them as sub_key=that word, no field\n",
    "            sub_key = remainder\n",
    "            field = None\n",
    "\n",
    "        # Retrieve or create sub-dict for (ogc_fid, sub_key)\n",
    "        subd = get_subdict(ogc_fid, sub_key)\n",
    "\n",
    "        # (A) If this row indicates the E+ object type\n",
    "        if field == \"obj_type\":\n",
    "            # e.g. assigned_value = \"MATERIAL:NOMASS\"\n",
    "            subd[\"obj_type\"] = assigned_value\n",
    "\n",
    "        # (B) If this row indicates the E+ object name\n",
    "        elif field == \"Name\":\n",
    "            subd[\"obj_name\"] = assigned_value\n",
    "\n",
    "        # (C) If the field ends with \"_range\", parse as min/max\n",
    "        elif field and field.endswith(\"_range\"):\n",
    "            # e.g. field=\"Thermal_Resistance_range\"\n",
    "            base_param = field.replace(\"_range\", \"\")  # \"Thermal_Resistance\"\n",
    "\n",
    "            if base_param not in subd[\"params\"]:\n",
    "                subd[\"params\"][base_param] = {\"value\": None, \"min\": None, \"max\": None}\n",
    "\n",
    "            # assigned_value might be something like \"(4.0, 5.0)\" or maybe \"None\"\n",
    "            try:\n",
    "                maybe_tuple = ast.literal_eval(str(assigned_value))\n",
    "                if isinstance(maybe_tuple, (list, tuple)) and len(maybe_tuple) == 2:\n",
    "                    min_val, max_val = maybe_tuple\n",
    "                    subd[\"params\"][base_param][\"min\"] = min_val\n",
    "                    subd[\"params\"][base_param][\"max\"] = max_val\n",
    "            except:\n",
    "                pass  # If parse fails or it's \"None\", we leave them as None\n",
    "\n",
    "        # (D) If it's a 'normal' field => param_name like \"Thermal_Resistance\"\n",
    "        else:\n",
    "            # If there's no field, we might be dealing with e.g. \"roughness\" or \"wwr\"\n",
    "            # which are top-level. We'll store them as a param anyway, in case you want them.\n",
    "            if field is None:\n",
    "                # e.g. sub_key=\"wwr\", so param_name = sub_key\n",
    "                # We'll store it under subd[\"params\"][sub_key] to keep it consistent\n",
    "                p_name = sub_key\n",
    "                if p_name not in subd[\"params\"]:\n",
    "                    subd[\"params\"][p_name] = {\"value\": None, \"min\": None, \"max\": None}\n",
    "                subd[\"params\"][p_name][\"value\"] = assigned_value\n",
    "            else:\n",
    "                # e.g. field=\"Thermal_Resistance\", assigned_value=4.23\n",
    "                if field not in subd[\"params\"]:\n",
    "                    subd[\"params\"][field] = {\"value\": None, \"min\": None, \"max\": None}\n",
    "                subd[\"params\"][field][\"value\"] = assigned_value\n",
    "\n",
    "    # Now finalize. We'll produce a row for **every** param in subd[\"params\"], even if\n",
    "    # param_value is None and min/max are None.\n",
    "\n",
    "    structured_rows = []\n",
    "    for (fid, s_key), info in final_dict.items():\n",
    "        obj_type = info[\"obj_type\"]\n",
    "        obj_name = info[\"obj_name\"]\n",
    "        params = info[\"params\"]  # a dict => param_name => { value, min, max }\n",
    "\n",
    "        # If no params => possibly skip if you want. But let's create NO row or a placeholder?\n",
    "        # We do NOT skip them if you want a row. But let's skip if sub_key has no params at all.\n",
    "        if not params:\n",
    "            # Possibly store a row for \"sub_key with no params\"? If you want that, do:\n",
    "            # structured_rows.append({ \"ogc_fid\": fid, \"sub_key\": s_key, ... })\n",
    "            # But typically we skip if no actual param.\n",
    "            continue\n",
    "\n",
    "        # For each param in \"params\"\n",
    "        for p_name, pvals in params.items():\n",
    "            param_value = pvals[\"value\"]\n",
    "            param_min = pvals[\"min\"]\n",
    "            param_max = pvals[\"max\"]\n",
    "\n",
    "            structured_rows.append({\n",
    "                \"ogc_fid\": fid,\n",
    "                \"sub_key\": s_key,\n",
    "                \"eplus_object_type\": obj_type,\n",
    "                \"eplus_object_name\": obj_name,\n",
    "                \"param_name\": p_name,\n",
    "                \"param_value\": param_value,  # might be None or empty\n",
    "                \"param_min\": param_min,      # might be None\n",
    "                \"param_max\": param_max       # might be None\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_out = pd.DataFrame(structured_rows)\n",
    "\n",
    "    # (Optional) attempt to float-convert param_value, param_min, param_max\n",
    "    def try_float(x):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except:\n",
    "            return x\n",
    "\n",
    "    for col in [\"param_value\", \"param_min\", \"param_max\"]:\n",
    "        df_out[col] = df_out[col].apply(try_float)\n",
    "\n",
    "    df_out.to_csv(csv_output, index=False)\n",
    "    print(f\"[transform_fenez_log_to_structured_with_ranges] => wrote: {csv_output}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transform_fenez_log_to_structured_with_ranges(\n",
    "        csv_input=\"output/assigned/assigned_fenez_params.csv\",\n",
    "        csv_output=\"output/assigned/structured_fenez_params.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Wrote building-level picks to D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_vent_building.csv\n",
      "[INFO] Wrote zone-level picks to D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_vent_zones.csv\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# flatten_assigned_vent.py\n",
    "###############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def parse_assigned_value(value_str):\n",
    "    \"\"\"\n",
    "    Safely convert the string in 'assigned_value' into a Python dict,\n",
    "    e.g. literal_eval(\"{'infiltration_base':1.23}\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ast.literal_eval(value_str)\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def flatten_ventilation_data(df_input, out_build_csv, out_zone_csv):\n",
    "    \"\"\"\n",
    "    Takes a DataFrame with columns [ogc_fid, param_name, assigned_value].\n",
    "    Splits it into two DataFrames:\n",
    "      1) building-level (flattening 'building_params')\n",
    "      2) zone-level (flattening 'zones').\n",
    "\n",
    "    Then writes them to CSV.\n",
    "    \"\"\"\n",
    "    building_rows = []\n",
    "    zone_rows = []\n",
    "\n",
    "    for idx, row in df_input.iterrows():\n",
    "        bldg_id = row[\"ogc_fid\"]\n",
    "        param_name = row[\"param_name\"]\n",
    "        assigned_val = row[\"assigned_value\"]  # should now be a dict\n",
    "\n",
    "        if param_name == \"building_params\":\n",
    "            # assigned_val is a dict of infiltration_base, year_factor, fan_pressure, etc.\n",
    "            for k, v in assigned_val.items():\n",
    "                building_rows.append({\n",
    "                    \"ogc_fid\": bldg_id,\n",
    "                    \"param_name\": k,\n",
    "                    \"param_value\": v\n",
    "                })\n",
    "\n",
    "        elif param_name == \"zones\":\n",
    "            # assigned_val is a dict: { \"Zone1\": {...}, \"Zone2\": {...}, ... }\n",
    "            for zone_name, zone_dict in assigned_val.items():\n",
    "                for zparam_name, zparam_val in zone_dict.items():\n",
    "                    zone_rows.append({\n",
    "                        \"ogc_fid\": bldg_id,\n",
    "                        \"zone_name\": zone_name,\n",
    "                        \"param_name\": zparam_name,\n",
    "                        \"param_value\": zparam_val\n",
    "                    })\n",
    "\n",
    "        else:\n",
    "            # If there's something else or you want to handle further data\n",
    "            pass\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_build = pd.DataFrame(building_rows)\n",
    "    df_zone = pd.DataFrame(zone_rows)\n",
    "\n",
    "    # Reorder columns if you like\n",
    "    df_build = df_build[[\"ogc_fid\", \"param_name\", \"param_value\"]]\n",
    "    df_zone = df_zone[[\"ogc_fid\", \"zone_name\", \"param_name\", \"param_value\"]]\n",
    "\n",
    "    # Write to CSV\n",
    "    df_build.to_csv(out_build_csv, index=False)\n",
    "    df_zone.to_csv(out_zone_csv, index=False)\n",
    "\n",
    "    print(f\"[INFO] Wrote building-level picks to {out_build_csv}\")\n",
    "    print(f\"[INFO] Wrote zone-level picks to {out_zone_csv}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1) Path to your original CSV\n",
    "    csv_in = r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_ventilation.csv\"\n",
    "\n",
    "    # 2) Paths for output\n",
    "    csv_build_out = r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_vent_building.csv\"\n",
    "    csv_zone_out = r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_vent_zones.csv\"\n",
    "\n",
    "    # 3) Read the CSV\n",
    "    df_assigned = pd.read_csv(csv_in)\n",
    "\n",
    "    # 4) Convert 'assigned_value' from string to dict\n",
    "    #    using 'ast.literal_eval' or a helper function\n",
    "    df_assigned[\"assigned_value\"] = df_assigned[\"assigned_value\"].apply(parse_assigned_value)\n",
    "\n",
    "    # 5) Flatten\n",
    "    flatten_ventilation_data(\n",
    "        df_input=df_assigned,\n",
    "        out_build_csv=csv_build_out,\n",
    "        out_zone_csv=csv_zone_out\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ogc_fid</th>\n",
       "      <th>param_name</th>\n",
       "      <th>assigned_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4136730</td>\n",
       "      <td>building_params</td>\n",
       "      <td>{'infiltration_base': 1.2278853596915769, 'inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4136730</td>\n",
       "      <td>zones</td>\n",
       "      <td>{'Zone1': {'infiltration_object_name': 'Infil_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4136732</td>\n",
       "      <td>building_params</td>\n",
       "      <td>{'infiltration_base': 0.6278853596915768, 'inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4136732</td>\n",
       "      <td>zones</td>\n",
       "      <td>{'Zone1_FrontPerimeter': {'infiltration_object...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ogc_fid       param_name                                     assigned_value\n",
       "0  4136730  building_params  {'infiltration_base': 1.2278853596915769, 'inf...\n",
       "1  4136730            zones  {'Zone1': {'infiltration_object_name': 'Infil_...\n",
       "2  4136732  building_params  {'infiltration_base': 0.6278853596915768, 'inf...\n",
       "3  4136732            zones  {'Zone1_FrontPerimeter': {'infiltration_object..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_assigned = pd.read_csv(r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_ventilation.csv\")\n",
    "df_assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Wrote building-level picks to D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_hvac_building.csv\n",
      "[INFO] Wrote zone-level picks to D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_hvac_zones.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def parse_assigned_value(value_str):\n",
    "    \"\"\"\n",
    "    Safely convert the string in 'assigned_value' into a Python dict.\n",
    "    Uses ast.literal_eval to parse e.g.\n",
    "      \"{'heating_day_setpoint': 20.28, 'cooling_day_setpoint': 24.55, ...}\"\n",
    "    into a real Python dictionary.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ast.literal_eval(value_str)\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def flatten_hvac_data(df_input, out_build_csv, out_zone_csv):\n",
    "    \"\"\"\n",
    "    Takes a DataFrame with columns [ogc_fid, param_name, assigned_value].\n",
    "    Splits it into two DataFrames:\n",
    "      1) building-level (where param_name == \"hvac_params\")\n",
    "      2) zone-level (where param_name == \"zones\").\n",
    "\n",
    "    Then writes them to CSV (out_build_csv, out_zone_csv).\n",
    "    \"\"\"\n",
    "    building_rows = []\n",
    "    zone_rows = []\n",
    "\n",
    "    for idx, row in df_input.iterrows():\n",
    "        bldg_id = row[\"ogc_fid\"]\n",
    "        param_name = row[\"param_name\"]\n",
    "        assigned_val = row[\"assigned_value\"]  # should be a dict\n",
    "\n",
    "        if param_name == \"hvac_params\":\n",
    "            # assigned_val is a dict with e.g.:\n",
    "            # {\n",
    "            #   \"heating_day_setpoint\": 20.2788,\n",
    "            #   \"heating_day_setpoint_range\": (19.0,21.0),\n",
    "            #   \"cooling_day_setpoint\": 24.55,\n",
    "            #   \"schedule_details\": {...},\n",
    "            #   etc.\n",
    "            # }\n",
    "            for k, v in assigned_val.items():\n",
    "                building_rows.append({\n",
    "                    \"ogc_fid\": bldg_id,\n",
    "                    \"param_name\": k,\n",
    "                    \"param_value\": v\n",
    "                })\n",
    "\n",
    "        elif param_name == \"zones\":\n",
    "            # assigned_val is a dict with zone_name => { \"hvac_object_name\": \"...\", ... }\n",
    "            for zone_name, zone_dict in assigned_val.items():\n",
    "                # zone_dict might be something like:\n",
    "                # {\n",
    "                #   \"hvac_object_name\": \"Zone1 Ideal Loads\",\n",
    "                #   \"hvac_object_type\": \"ZONEHVAC:IDEALLOADSAIRSYSTEM\",\n",
    "                #   ...\n",
    "                # }\n",
    "                for zparam, zval in zone_dict.items():\n",
    "                    zone_rows.append({\n",
    "                        \"ogc_fid\": bldg_id,\n",
    "                        \"zone_name\": zone_name,\n",
    "                        \"param_name\": zparam,\n",
    "                        \"param_value\": zval\n",
    "                    })\n",
    "\n",
    "        else:\n",
    "            # If there's any other param_name, skip or handle differently\n",
    "            pass\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_build = pd.DataFrame(building_rows)\n",
    "    df_zone = pd.DataFrame(zone_rows)\n",
    "\n",
    "    # Optional: reorder columns\n",
    "    df_build = df_build[[\"ogc_fid\", \"param_name\", \"param_value\"]]\n",
    "    df_zone = df_zone[[\"ogc_fid\", \"zone_name\", \"param_name\", \"param_value\"]]\n",
    "\n",
    "    # Write to CSV\n",
    "    df_build.to_csv(out_build_csv, index=False)\n",
    "    df_zone.to_csv(out_zone_csv, index=False)\n",
    "\n",
    "    print(f\"[INFO] Wrote building-level picks to {out_build_csv}\")\n",
    "    print(f\"[INFO] Wrote zone-level picks to {out_zone_csv}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1) Path to your original HVAC CSV file\n",
    "    csv_in = r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_hvac_params.csv\"\n",
    "\n",
    "    # 2) Paths for output CSVs\n",
    "    csv_build_out = r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_hvac_building.csv\"\n",
    "    csv_zone_out = r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_hvac_zones.csv\"\n",
    "\n",
    "    # 3) Load the CSV\n",
    "    df_assigned = pd.read_csv(csv_in)\n",
    "\n",
    "    # 4) Convert assigned_value from string to dict\n",
    "    df_assigned[\"assigned_value\"] = df_assigned[\"assigned_value\"].apply(parse_assigned_value)\n",
    "\n",
    "    # 5) Flatten\n",
    "    flatten_hvac_data(\n",
    "        df_input=df_assigned,\n",
    "        out_build_csv=csv_build_out,\n",
    "        out_zone_csv=csv_zone_out\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Wrote building-level picks to D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_hvac_building.csv\n",
      "[INFO] Wrote zone-level picks to D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_hvac_zones.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[transform_dhw_log_to_structured] => Wrote structured CSV to D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_dhw_params.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # for safely parsing a tuple string like \"(4.0, 5.0)\"\n",
    "\n",
    "\n",
    "def transform_dhw_log_to_structured(\n",
    "    csv_input=\"output/assigned/assigned_dhw_params.csv\",\n",
    "    csv_output=\"output/assigned/structured_dhw_params.csv\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads the 'flat' DHW CSV with columns (ogc_fid, param_name, assigned_value).\n",
    "    Produces a 'structured' CSV with columns:\n",
    "       ogc_fid, sub_key, eplus_object_type, eplus_object_name,\n",
    "       param_name, param_value, param_min, param_max\n",
    "\n",
    "    Key logic:\n",
    "      - If param_name ends with \"_range\", parse min/max from assigned_value\n",
    "        and store them in memory.\n",
    "      - If param_name is the same as the range version minus \"_range\",\n",
    "        unify them in one row => param_value + param_min + param_max.\n",
    "      - For E+ objects (like \"dhw_waterheater.obj_type\"), store them\n",
    "        so we can fill eplus_object_type/eplus_object_name in the final row.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(csv_input)\n",
    "\n",
    "    # We'll keep data in a nested dictionary:\n",
    "    # final_dict[(ogc_fid, sub_key, base_param)] = {\n",
    "    #    \"value\": <float or str>,\n",
    "    #    \"min\": <float or None>,\n",
    "    #    \"max\": <float or None>,\n",
    "    #    \"obj_type\": <str or None>,\n",
    "    #    \"obj_name\": <str or None>\n",
    "    # }\n",
    "    final_dict = {}\n",
    "\n",
    "    def get_subdict(fid, s_key, base_param):\n",
    "        if (fid, s_key, base_param) not in final_dict:\n",
    "            final_dict[(fid, s_key, base_param)] = {\n",
    "                \"value\": None,\n",
    "                \"min\": None,\n",
    "                \"max\": None,\n",
    "                \"obj_type\": None,\n",
    "                \"obj_name\": None\n",
    "            }\n",
    "        return final_dict[(fid, s_key, base_param)]\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        # Must have these columns\n",
    "        if \"ogc_fid\" not in row or \"param_name\" not in row or \"assigned_value\" not in row:\n",
    "            continue\n",
    "\n",
    "        ogc_fid = row[\"ogc_fid\"]\n",
    "        param_name = str(row[\"param_name\"])\n",
    "        assigned_value = row[\"assigned_value\"]\n",
    "\n",
    "        # We'll skip non-DHW if your CSV might have geometry/hvac. \n",
    "        # Or you can remove this if everything is DHW:\n",
    "        if not param_name.startswith(\"dhw_\"):\n",
    "            # We'll keep it here in case you only want to transform \"dhw_*\"\n",
    "            pass\n",
    "\n",
    "        # 1) If we see something like \"dhw_waterheater.obj_type\" => E+ object type\n",
    "        #    or \"dhw_waterheater.Name\" => E+ object name\n",
    "        # We'll parse sub_key = \"dhw_waterheater\" and field = \"obj_type\" or \"Name\".\n",
    "        # Then we store them so we can fill them in final output.\n",
    "\n",
    "        # 2) If we see something like \"occupant_density_m2_per_person_range\",\n",
    "        #    we parse the range => (minVal, maxVal).\n",
    "        # 3) If we see \"occupant_density_m2_per_person\", that's the final pick.\n",
    "\n",
    "        # Let's parse the sub_key from param_name, if there's a dot, e.g. \n",
    "        # \"dhw_waterheater.obj_type\" => sub_key=\"dhw_waterheater\", field=\"obj_type\"\n",
    "        # If no dot => sub_key = \"dhw\", field = rest?\n",
    "\n",
    "        sub_key = \"dhw_top\"  # default if we don't find anything\n",
    "        field = param_name\n",
    "        if '.' in param_name:\n",
    "            # e.g. \"dhw_waterheater.obj_type\"\n",
    "            sub_key, field = param_name.rsplit('.', 1)  # split from right\n",
    "\n",
    "        if field.endswith(\"_range\"):\n",
    "            # e.g. \"occupant_density_m2_per_person_range\"\n",
    "            base_param = field[:-6]  # remove \"_range\"\n",
    "            subd = get_subdict(ogc_fid, sub_key, base_param)\n",
    "\n",
    "            # parse assigned_value => (minVal, maxVal)\n",
    "            # e.g. \"(27.0, 33.0)\"\n",
    "            try:\n",
    "                tval = ast.literal_eval(str(assigned_value))\n",
    "                if isinstance(tval, (list, tuple)) and len(tval) == 2:\n",
    "                    subd[\"min\"], subd[\"max\"] = tval\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        elif field in (\"obj_type\", \"Name\"):\n",
    "            # It's an E+ object pointer\n",
    "            # store them in subdict => base_param = \"EPOBJ\" or something\n",
    "            # Actually, let's define base_param = \"\" so we handle it as an object-level thing\n",
    "            base_param = \"EPOBJ\"\n",
    "            subd = get_subdict(ogc_fid, sub_key, base_param)\n",
    "\n",
    "            if field == \"obj_type\":\n",
    "                subd[\"obj_type\"] = assigned_value\n",
    "            else:  # field==\"Name\"\n",
    "                subd[\"obj_name\"] = assigned_value\n",
    "\n",
    "        else:\n",
    "            # normal param => occupant_density_m2_per_person\n",
    "            # or \"dhw_daily_liters\"\n",
    "            base_param = field\n",
    "            subd = get_subdict(ogc_fid, sub_key, base_param)\n",
    "\n",
    "            # try to interpret as float\n",
    "            subd[\"value\"] = assigned_value\n",
    "\n",
    "    # Now we have a dict that merges range with final value, object type, etc.\n",
    "    # We'll produce final rows with columns we want:\n",
    "    structured_rows = []\n",
    "    for (fid, s_key, base_param), valdict in final_dict.items():\n",
    "        # If base_param == \"EPOBJ\", that means it's the object reference (obj_type, obj_name)\n",
    "        # Usually, we want to store them in param_name => \"obj_type\" or \"object_name\".\n",
    "        # But let's unify everything in \"param_name, param_value\".\n",
    "        # We handle that scenario if the user wants an actual param row or skip it.\n",
    "        # We'll separate them out below.\n",
    "\n",
    "        # If the user wants a single param row for occupant_density, occupant_density_range, etc.:\n",
    "        if base_param == \"EPOBJ\":\n",
    "            # This indicates the sub_key is an E+ object prefix like \"dhw_waterheater\"\n",
    "            # valdict might have obj_type => \"WATERHEATER:MIXED\" and obj_name => \"MyDHW_0_WaterHeater\"\n",
    "            # We'll store them as \"eplus_object_type\" and \"eplus_object_name\" so that\n",
    "            # *other* param rows can refer to them.\n",
    "\n",
    "            # we won't produce a row for EPOBJ itself, because it doesn't correspond\n",
    "            # to a normal param. We'll store it so that we can fill in the final eplus_object_type\n",
    "            # eplus_object_name for all rows with sub_key = s_key, if we want.\n",
    "            pass\n",
    "        else:\n",
    "            # It's a normal param => occupant_density_m2_per_person, setpoint_c, etc.\n",
    "            param_name = base_param\n",
    "            param_val = valdict[\"value\"]\n",
    "            param_min = valdict[\"min\"]\n",
    "            param_max = valdict[\"max\"]\n",
    "\n",
    "            # We'll parse them as floats if possible:\n",
    "            def try_float(x):\n",
    "                try:\n",
    "                    return float(x)\n",
    "                except:\n",
    "                    return x\n",
    "\n",
    "            param_val = try_float(param_val)\n",
    "            param_min = try_float(param_min)\n",
    "            param_max = try_float(param_max)\n",
    "\n",
    "            # eplus object type & name if we find them from \"EPOBJ\"\n",
    "            # let's see if there's a subdict with base_param=\"EPOBJ\" for this sub_key\n",
    "            ep_obj = final_dict.get((fid, s_key, \"EPOBJ\"), {})\n",
    "            eplus_type = ep_obj.get(\"obj_type\", None)\n",
    "            eplus_name = ep_obj.get(\"obj_name\", None)\n",
    "\n",
    "            structured_rows.append({\n",
    "                \"ogc_fid\": fid,\n",
    "                \"sub_key\": s_key,\n",
    "                \"eplus_object_type\": eplus_type,\n",
    "                \"eplus_object_name\": eplus_name,\n",
    "                \"param_name\": param_name,\n",
    "                \"param_value\": param_val,\n",
    "                \"param_min\": param_min,\n",
    "                \"param_max\": param_max\n",
    "            })\n",
    "\n",
    "    # Additionally, we might want a row for the object-level fields (obj_type, obj_name).\n",
    "    # e.g., param_name=\"obj_type\" => param_value=\"WATERHEATER:MIXED\"\n",
    "    #        param_name=\"Name\" => param_value=\"MyDHW_0_WaterHeater\"\n",
    "    # We'll do a second pass for those \"EPOBJ\" entries if you want them each as a row.\n",
    "\n",
    "    object_rows = []\n",
    "    for (fid, s_key, base_param), valdict in final_dict.items():\n",
    "        if base_param == \"EPOBJ\":\n",
    "            # It's an object definition => let's produce 2 param rows:\n",
    "            eplus_type = valdict[\"obj_type\"]\n",
    "            eplus_name = valdict[\"obj_name\"]\n",
    "\n",
    "            # param_name=\"obj_type\"\n",
    "            object_rows.append({\n",
    "                \"ogc_fid\": fid,\n",
    "                \"sub_key\": s_key,\n",
    "                \"eplus_object_type\": eplus_type,   # we can store it again\n",
    "                \"eplus_object_name\": eplus_name,   # or keep these blank\n",
    "                \"param_name\": \"obj_type\",\n",
    "                \"param_value\": eplus_type,\n",
    "                \"param_min\": None,\n",
    "                \"param_max\": None\n",
    "            })\n",
    "            # param_name=\"Name\"\n",
    "            object_rows.append({\n",
    "                \"ogc_fid\": fid,\n",
    "                \"sub_key\": s_key,\n",
    "                \"eplus_object_type\": eplus_type,\n",
    "                \"eplus_object_name\": eplus_name,\n",
    "                \"param_name\": \"Name\",\n",
    "                \"param_value\": eplus_name,\n",
    "                \"param_min\": None,\n",
    "                \"param_max\": None\n",
    "            })\n",
    "\n",
    "    # Combine them\n",
    "    all_rows = structured_rows + object_rows\n",
    "    df_struct = pd.DataFrame(all_rows)\n",
    "\n",
    "    # Sort rows so the object-level lines appear first or last. Not strictly needed:\n",
    "    df_struct.sort_values(by=[\"ogc_fid\", \"sub_key\", \"param_name\"], inplace=True)\n",
    "\n",
    "    df_struct.to_csv(csv_output, index=False)\n",
    "    print(f\"[transform_dhw_log_to_structured] => Wrote structured CSV to {csv_output}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transform_dhw_log_to_structured(\n",
    "        csv_input=r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_dhw_params.csv\",\n",
    "        csv_output=r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\assigned_dhw_params.csv\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDsaie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
