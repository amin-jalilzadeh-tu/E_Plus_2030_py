Folder: D:\Documents\E_Plus_2030_py\validation

  File: compare_sims_with_measured.py
  --- File Contents Start ---
# validation/compare_sims_with_measured.py
import pandas as pd

def load_csv_as_df(real_data_path, sim_data_path):
    """
    Loads real and simulated data from CSV into DataFrames.
    Just a simple utility function, used if needed.
    """
    print(f"[DEBUG] Loading real data from: {real_data_path}")
    print(f"[DEBUG] Loading sim data  from: {sim_data_path}")

    df_real = pd.read_csv(real_data_path)
    df_sim  = pd.read_csv(sim_data_path)

    print("[DEBUG] df_real shape:", df_real.shape)
    print("[DEBUG] df_sim  shape:", df_sim.shape)
    print("[DEBUG] df_real columns:", df_real.columns.to_list())
    print("[DEBUG] df_sim columns: ", df_sim.columns.to_list())
    return df_real, df_sim


def align_data_for_variable(df_real, df_sim, real_building_id, sim_building_id, variable_name):
    """
    Returns aligned arrays of sim vs. obs for a given (real_building_id, sim_building_id, variable).
    - df_real and df_sim should be *already filtered* to the appropriate building + var
      (i.e., df_real_sub, df_sim_sub).
    - This function melts them from wide to long format and merges on 'Date'.

    Returns: (sim_values_array, obs_values_array, merged_dataframe)
    """

    # 1) Filter again for safety, though presumably df_real and df_sim are already subset
    real_sel = df_real[
        (df_real['BuildingID'] == real_building_id) &
        (df_real['VariableName'] == variable_name)
    ]
    sim_sel  = df_sim[
        (df_sim['BuildingID'] == sim_building_id) &
        (df_sim['VariableName'] == variable_name)
    ]

    # Debug prints
    print(f"   > Aligning real Bldg={real_building_id} vs sim Bldg={sim_building_id}, Var={variable_name}")
    print(f"   > real_sel shape={real_sel.shape}, sim_sel shape={sim_sel.shape}")

    # If empty, return empty arrays
    if real_sel.empty or sim_sel.empty:
        return [], [], pd.DataFrame()

    # 2) Melt from wide to long
    real_long = real_sel.melt(
        id_vars=['BuildingID','VariableName'],
        var_name='Date',
        value_name='Value'
    ).dropna(subset=['Value'])

    sim_long = sim_sel.melt(
        id_vars=['BuildingID','VariableName'],
        var_name='Date',
        value_name='Value'
    ).dropna(subset=['Value'])

    # 3) Merge on 'Date'
    merged = pd.merge(
        real_long[['Date','Value']],
        sim_long[['Date','Value']],
        on='Date', how='inner', suffixes=('_obs','_sim')
    )

    # 4) Return arrays plus the merged DataFrame
    return merged['Value_sim'].values, merged['Value_obs'].values, merged

  --- File Contents End ---

  File: main_validation.py
  --- File Contents Start ---
# main_validation.py
"""
validation/main_validation.py

This module provides a reusable function `run_validation_process` that:
- Reads user config for validation
- Calls validate_with_ranges(...) from validate_results_custom.py
- Prints and saves a CSV of metrics
- Optionally generates a bar chart (or time-series/scatter) if skip_plots is False

Added Feature:
- Uses config["variables_to_compare"] to restrict which VariableNames to validate.

Dependencies (unchanged):
- validation.compare_sims_with_measured
- validation.metrics
- validation.validate_results_custom (must be updated to accept `variables_to_compare`)
- validation.visualize
"""

import csv
import matplotlib.pyplot as plt

from validation.validate_results_custom import validate_with_ranges

def run_validation_process(config):
    """
    Runs a validation process based on a user config dict.

    Example config structure:
    {
        "real_data_csv": "path/to/real_data.csv",
        "sim_data_csv":  "path/to/sim_data.csv",
        "bldg_ranges":   { "0": [0, 1, 2], "1": [1] },
        "variables_to_compare": [
            "Electricity:Facility [J](Hourly)",
            "Heating:EnergyTransfer [J](Hourly)"
        ],
        "threshold_cv_rmse": 30.0,
        "skip_plots": false,
        "output_csv": "validation_report.csv"
    }
    """

    # 1) Extract config values
    real_data_csv     = config.get("real_data_csv", "")
    sim_data_csv      = config.get("sim_data_csv", "")
    bldg_ranges       = config.get("bldg_ranges", {})
    threshold_cv_rmse = config.get("threshold_cv_rmse", 30.0)
    skip_plots        = config.get("skip_plots", False)
    output_csv        = config.get("output_csv", "validation_report.csv")

    # NEW: A list of variable names to compare
    variables_to_compare = config.get("variables_to_compare", [])

    print(f"[INFO] Starting validation with:")
    print(f"   Real data CSV = {real_data_csv}")
    print(f"   Sim  data CSV = {sim_data_csv}")
    print(f"   Building Ranges = {bldg_ranges}")
    print(f"   Variables to Compare = {variables_to_compare}")
    print(f"   Threshold CV(RMSE) = {threshold_cv_rmse}")
    print(f"   skip_plots = {skip_plots}")
    print(f"   output_csv = {output_csv}")

    # 2) Call validate_with_ranges
    metric_results = validate_with_ranges(
        real_data_path=real_data_csv,
        sim_data_path=sim_data_csv,
        bldg_ranges=bldg_ranges,
        variables_to_compare=variables_to_compare,   # pass in the new argument
        threshold_cv_rmse=threshold_cv_rmse,
        skip_plots=skip_plots
    )

    # 3) Print summary to console
    print("\n=== Validation Summary ===")
    for (real_bldg, sim_bldg, var_name), mvals in metric_results.items():
        print(
            f"Real={real_bldg}, Sim={sim_bldg}, Var={var_name} => "
            f"MBE={mvals['MBE']:.2f}, "
            f"CV(RMSE)={mvals['CVRMSE']:.2f}, "
            f"NMBE={mvals['NMBE']:.2f}, "
            f"Pass={mvals['Pass']}"
        )

    # 4) Save metrics to CSV
    print(f"\n[INFO] Saving metrics to {output_csv}")
    with open(output_csv, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["RealBldg", "SimBldg", "VariableName", "MBE", "CVRMSE", "NMBE", "Pass"])
        for (real_bldg, sim_bldg, var_name), mvals in metric_results.items():
            writer.writerow([
                real_bldg,
                sim_bldg,
                var_name,
                f"{mvals['MBE']:.2f}",
                f"{mvals['CVRMSE']:.2f}",
                f"{mvals['NMBE']:.2f}",
                mvals['Pass']
            ])

    # 5) Check for calibration triggers if CV(RMSE) fails
    print("\n=== Checking for Calibration Needs ===")
    for (real_bldg, sim_bldg, var_name), mvals in metric_results.items():
        if not mvals['Pass']:
            print(
                f"[CALIBRATION] RealBldg={real_bldg}, SimBldg={sim_bldg}, Var={var_name}: "
                f"CV(RMSE)={mvals['CVRMSE']:.2f}% > threshold => Trigger calibration steps..."
            )

    # 6) Optional bar chart: CV(RMSE) for each (RealBldg, SimBldg, Var)
    #    We'll define an inline function here or import from visualize.
    bar_chart_metrics_for_triple(metric_results, title="CV(RMSE) Validation (Per Real vs. Sim)")

def bar_chart_metrics_for_triple(metric_dict, title="Validation Metrics"):
    """
    Create a bar chart of CV(RMSE) for each (RealBldg, SimBldg, Var).
    Bars are green if pass, red if fail.
    """
    if not metric_dict:
        print("[DEBUG] No metrics to plot - metric_dict is empty.")
        return

    labels = []
    cvrmse_values = []
    pass_status = []

    for (real_bldg, sim_bldg, var_name), mvals in metric_dict.items():
        label = f"R{real_bldg}-S{sim_bldg}-{var_name}"
        labels.append(label)
        cvrmse_values.append(mvals['CVRMSE'])
        pass_status.append(mvals['Pass'])

    x = range(len(labels))

    plt.figure(figsize=(12, 6))
    bars = plt.bar(x, cvrmse_values, alpha=0.7)

    for i, bar in enumerate(bars):
        bar.set_color('green' if pass_status[i] else 'red')

    plt.xticks(list(x), labels, rotation=45, ha='right')
    plt.ylabel("CV(RMSE) (%)")
    plt.title(title)
    if cvrmse_values:
        plt.ylim(0, max(cvrmse_values)*1.1)
    plt.tight_layout()
    plt.show()

  --- File Contents End ---

  File: metrics.py
  --- File Contents Start ---
# validation/metrics.py
import numpy as np

def mean_bias_error(sim_values, obs_values):
    """
    MBE = ( sum(obs_i - sim_i) / sum(obs_i) ) * 100
    """
    sim = np.array(sim_values, dtype=float)
    obs = np.array(obs_values, dtype=float)
    denominator = np.sum(obs)
    if denominator == 0:
        return float('nan')
    mbe = (np.sum(obs - sim) / denominator) * 100.0
    return mbe

def cv_rmse(sim_values, obs_values):
    """
    CV(RMSE) = ( RMSE / mean(obs) ) * 100
    """
    sim = np.array(sim_values, dtype=float)
    obs = np.array(obs_values, dtype=float)
    obs_mean = np.mean(obs)
    if obs_mean == 0:
        return float('nan')
    mse = np.mean((obs - sim)**2)
    rmse = np.sqrt(mse)
    return (rmse / obs_mean) * 100.0

def nmbe(sim_values, obs_values):
    """
    NMBE = 100 * ( sum(obs_i - sim_i) / (n * mean(obs)) )
    """
    sim = np.array(sim_values, dtype=float)
    obs = np.array(obs_values, dtype=float)
    n = len(sim)
    obs_mean = np.mean(obs)
    if obs_mean == 0:
        return float('nan')
    nmbe_val = 100.0 * (np.sum(obs - sim) / (n * obs_mean))
    return nmbe_val

  --- File Contents End ---

  File: validate_results_custom.py
  --- File Contents Start ---
# validation/validate_results_custom.py

import pandas as pd

from validation.compare_sims_with_measured import align_data_for_variable
from validation.metrics import mean_bias_error, cv_rmse, nmbe
from validation.visualize import (
    plot_time_series_comparison,
    scatter_plot_comparison,
)

def validate_with_ranges(
    real_data_path,
    sim_data_path,
    bldg_ranges,
    variables_to_compare=None,
    threshold_cv_rmse=30.0,
    skip_plots=False
):
    """
    Compare real vs sim data for specified building mappings and variable names.

    :param real_data_path: Path to the CSV file with real data
    :param sim_data_path: Path to the CSV file with sim data
    :param bldg_ranges: dict mapping real_bldg (string) -> list of sim_bldgs. 
                       e.g. {"0": [0, 1, 2]}, or {"4136730": ["4136730"]}
    :param variables_to_compare: list of variable names (strings) to be validated.
    :param threshold_cv_rmse: pass/fail threshold for CV(RMSE) in percent
    :param skip_plots: if True, disable time-series and scatter plots
    :return: a dict of metrics keyed by (real_bldg, sim_bldg, variable_name)
    """

    if variables_to_compare is None:
        # If none provided, default to empty => no variables will be compared
        variables_to_compare = []

    # 1) Load the CSVs
    df_real = pd.read_csv(real_data_path)
    df_sim  = pd.read_csv(sim_data_path)

    # 2) Clean up any trailing whitespace in VariableName
    df_real["VariableName"] = df_real["VariableName"].astype(str).str.strip()
    df_sim["VariableName"]  = df_sim["VariableName"].astype(str).str.strip()

    # 3) Initialize a results dictionary
    results = {}

    # 4) Keep track of missing variables for debug
    missing_in_real = []
    missing_in_sim  = []

    # 5) Iterate over building mappings
    for real_bldg_str, sim_bldg_list in bldg_ranges.items():
        # Convert the real building ID from string to int
        # (If your CSV has building IDs as int64, this ensures a match)
        try:
            real_bldg = int(real_bldg_str)
        except ValueError:
            print(f"[WARN] Could not convert real building '{real_bldg_str}' to int; skipping.")
            continue

        # Subset real data for this real_bldg
        df_real_sub = df_real[df_real["BuildingID"] == real_bldg]
        if df_real_sub.empty:
            print(f"[WARN] No real data for building {real_bldg}")
            continue

        for sb in sim_bldg_list:
            # If the sim building is a string, also convert it to int
            try:
                sim_bldg = int(sb)
            except ValueError:
                print(f"[WARN] Could not convert sim building '{sb}' to int; skipping.")
                continue

            # Subset sim data for this sim_bldg
            df_sim_sub = df_sim[df_sim["BuildingID"] == sim_bldg]
            if df_sim_sub.empty:
                print(f"[WARN] No sim data for building {sim_bldg}")
                continue

            # 6) Loop over user-specified variables
            for var_name in variables_to_compare:
                # Check presence in real data
                if var_name not in df_real_sub["VariableName"].unique():
                    missing_in_real.append((real_bldg, var_name))
                    continue

                # Check presence in sim data
                if var_name not in df_sim_sub["VariableName"].unique():
                    missing_in_sim.append((sim_bldg, var_name))
                    continue

                # 7) Align data
                sim_vals, obs_vals, merged_df = align_data_for_variable(
                    df_real_sub,
                    df_sim_sub,
                    real_bldg,
                    sim_bldg,
                    var_name
                )

                # If no overlap or empty arrays, skip
                if len(sim_vals) == 0 or len(obs_vals) == 0:
                    print(f"[WARN] No overlap in dates for RealBldg={real_bldg}, SimBldg={sim_bldg}, Var={var_name}")
                    continue

                # 8) Compute metrics
                this_mbe   = mean_bias_error(sim_vals, obs_vals)
                this_cvrmse = cv_rmse(sim_vals, obs_vals)
                this_nmbe  = nmbe(sim_vals, obs_vals)

                pass_fail = False
                if this_cvrmse is not None and not (this_cvrmse is float('nan')):
                    pass_fail = (this_cvrmse < threshold_cv_rmse)

                # 9) Store results
                results[(real_bldg, sim_bldg, var_name)] = {
                    "MBE":    this_mbe,
                    "CVRMSE": this_cvrmse,
                    "NMBE":   this_nmbe,
                    "Pass":   pass_fail
                }

                # 10) Optionally plot
                if not skip_plots:
                    label_for_plot = f"{real_bldg}_VS_{sim_bldg}"
                    plot_time_series_comparison(merged_df, label_for_plot, var_name)
                    scatter_plot_comparison(merged_df, label_for_plot, var_name)

    # 11) Print missing variable info
    if missing_in_real:
        print("\n[INFO] Variables missing in REAL data for these (Building, Var):")
        unique_missing_real = set(missing_in_real)
        for (bldg, var) in unique_missing_real:
            print(f"   - RealBldg={bldg}, Var={var}")

    if missing_in_sim:
        print("\n[INFO] Variables missing in SIM data for these (Building, Var):")
        unique_missing_sim = set(missing_in_sim)
        for (bldg, var) in unique_missing_sim:
            print(f"   - SimBldg={bldg}, Var={var}")

    # Return the final dictionary of metrics
    return results

  --- File Contents End ---

  File: visualize.py
  --- File Contents Start ---
# validation/visualize.py
import matplotlib.pyplot as plt

def plot_time_series_comparison(merged_df, building_id, variable_name):
    """
    Creates a simple line plot comparing sim vs. obs over time 
    (e.g., 01-Jan, 02-Jan, etc.).
    merged_df has columns: Date, Value_obs, Value_sim
    """
    if merged_df.empty:
        print(f"[DEBUG] No data to plot for Bldg={building_id}, Var={variable_name}")
        return

    x_vals = merged_df['Date']  # might be strings like '01-Jan'
    obs_vals = merged_df['Value_obs']
    sim_vals = merged_df['Value_sim']

    plt.figure(figsize=(10,6))
    plt.plot(x_vals, obs_vals, 'o-', label='Observed')
    plt.plot(x_vals, sim_vals, 's-', label='Simulated')

    plt.title(f"Building {building_id} - {variable_name}")
    plt.xlabel("Date")
    plt.ylabel("Value")
    plt.legend()
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

def scatter_plot_comparison(merged_df, building_id, variable_name):
    """
    Creates a scatter plot of Observed vs. Simulated for a quick correlation check.
    """
    if merged_df.empty:
        print(f"[DEBUG] No data to plot scatter for Bldg={building_id}, Var={variable_name}")
        return

    obs_vals = merged_df['Value_obs']
    sim_vals = merged_df['Value_sim']

    plt.figure(figsize=(6,6))
    plt.scatter(obs_vals, sim_vals, alpha=0.7)
    # 1:1 line
    mn, mx = min(obs_vals.min(), sim_vals.min()), max(obs_vals.max(), sim_vals.max())
    plt.plot([mn, mx], [mn, mx], color='red', linestyle='--', label='1:1 line')

    plt.title(f"Scatter Comparison: Bldg={building_id}, Var={variable_name}")
    plt.xlabel("Observed")
    plt.ylabel("Simulated")
    plt.legend()
    plt.tight_layout()
    plt.show()

def bar_chart_metrics(metric_dict, title="Validation Metrics"):
    """
    Suppose metric_dict is e.g.:
      {
        (0, 'Cooling'): {'MBE': 2.3, 'CVRMSE': 18.5, 'NMBE': -0.4, 'Pass': True},
        (0, 'Heating'): { ... },
        (1, 'Cooling'): { ... },
        ...
      }
    We'll create a bar chart of CV(RMSE) across all keys.
    """
    import numpy as np

    if not metric_dict:
        print("[DEBUG] No metrics to plot - metric_dict is empty.")
        return

    labels = []
    cvrmse_values = []
    pass_status = []

    for (b_id, var), mvals in metric_dict.items():
        label = f"B{b_id}-{var}"
        labels.append(label)
        cvrmse_values.append(mvals['CVRMSE'])
        pass_status.append(mvals['Pass'])

    x = range(len(labels))

    plt.figure(figsize=(10,5))
    bars = plt.bar(x, cvrmse_values, color='blue', alpha=0.6)

    # Color code pass/fail if you want:
    for i, bar in enumerate(bars):
        if pass_status[i]:
            bar.set_color('green')
        else:
            bar.set_color('red')

    plt.xticks(list(x), labels, rotation=45, ha='right')
    plt.ylabel("CV(RMSE) (%)")
    plt.title(title)

    if cvrmse_values:
        plt.ylim(0, max(cvrmse_values)*1.1)
    plt.tight_layout()
    plt.show()

  --- File Contents End ---

================================================================================

Folder: D:\Documents\E_Plus_2030_py\validation\__pycache__

================================================================================

