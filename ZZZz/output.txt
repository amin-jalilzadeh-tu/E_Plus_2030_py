Folder: D:\Documents\E_Plus_2030_py\validation

  File: compare_sims_with_measured.py
  --- File Contents Start ---
# validation/compare_sims_with_measured.py
import pandas as pd

def load_csv_as_df(real_data_path, sim_data_path):
    """
    Loads real and simulated data from CSV into DataFrames.
    """
    print(f"[DEBUG] Loading real data from: {real_data_path}")
    print(f"[DEBUG] Loading sim data  from: {sim_data_path}")

    df_real = pd.read_csv(real_data_path)
    df_sim  = pd.read_csv(sim_data_path)

    print("[DEBUG] df_real shape:", df_real.shape)
    print("[DEBUG] df_sim  shape:", df_sim.shape)
    print("[DEBUG] df_real columns:", df_real.columns.to_list())
    print("[DEBUG] df_sim columns: ", df_sim.columns.to_list())
    return df_real, df_sim

def align_data_for_variable(df_real, df_sim, real_building_id, sim_building_id, variable_name):
    """
    Returns aligned arrays of sim vs. obs for a given (real_building_id, sim_building_id, variable).
    """
    # 1) Subset real
    real_sel = df_real[
        (df_real['BuildingID'] == real_building_id) &
        (df_real['VariableName'] == variable_name)
    ]

    # 2) Subset sim
    sim_sel = df_sim[
        (df_sim['BuildingID'] == sim_building_id) &
        (df_sim['VariableName'] == variable_name)
    ]

    print(f"   > Aligning real Bldg={real_building_id} vs sim Bldg={sim_building_id}, Var={variable_name}")
    print(f"   > real_sel shape={real_sel.shape}, sim_sel shape={sim_sel.shape}")

    if real_sel.empty or sim_sel.empty:
        return [], [], pd.DataFrame()

    # 3) Melt from wide to long
    real_long = real_sel.melt(
        id_vars=['BuildingID','VariableName'],
        var_name='Date', 
        value_name='Value'
    ).dropna(subset=['Value'])

    sim_long = sim_sel.melt(
        id_vars=['BuildingID','VariableName'],
        var_name='Date', 
        value_name='Value'
    ).dropna(subset=['Value'])

    # 4) Merge on 'Date'
    merged = pd.merge(
        real_long[['Date','Value']], 
        sim_long[['Date','Value']],
        on='Date', how='inner', suffixes=('_obs','_sim')
    )

    return merged['Value_sim'].values, merged['Value_obs'].values, merged


  --- File Contents End ---

  File: main_validation.py
  --- File Contents Start ---
# main.py

from validation.validate_results_custom import validate_with_ranges
import matplotlib.pyplot as plt
import csv

def main():
    real_data_csv = r"D:\Documents\E_Plus_2030_py\output\results\mock_merged_daily_mean.csv"
    sim_data_csv  = r"D:\Documents\E_Plus_2030_py\output\results\merged_daily_mean_mocked.csv"

    # Example: Compare real building 0 vs. sim buildings [0..4] individually
    bldg_ranges = {
        0: range(0, 5)
        # If you also want real bldg=1 to compare vs. sim bldgs [0..4], do:
        # 1: range(0, 5)
        # etc.
    }

    print("=== Starting Validation with bldg_ranges ===")
    metric_results = validate_with_ranges(
        real_data_path=real_data_csv,
        sim_data_path=sim_data_csv,
        bldg_ranges=bldg_ranges,
        threshold_cv_rmse=30.0
    )

    # ---------------------------------------------------
    # Print summary for each (RealBldg, SimBldg, Variable)
    # ---------------------------------------------------
    print("\n=== Validation Summary ===")
    for (real_bldg, sim_bldg, var_name), mvals in metric_results.items():
        print(f"Real={real_bldg}, Sim={sim_bldg}, Var={var_name} => "
              f"MBE={mvals['MBE']:.2f}, CV(RMSE)={mvals['CVRMSE']:.2f}, "
              f"NMBE={mvals['NMBE']:.2f}, Pass={mvals['Pass']}")

    # ---------------------------------------------------
    # Save metrics to CSV
    #   with columns: RealBldg, SimBldg, VariableName, ...
    # ---------------------------------------------------
    output_csv = "validation_report.csv"
    print(f"\n[INFO] Saving metrics to {output_csv}")
    with open(output_csv, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["RealBldg", "SimBldg", "VariableName", "MBE", "CVRMSE", "NMBE", "Pass"])
        for (real_bldg, sim_bldg, var_name), mvals in metric_results.items():
            writer.writerow([
                real_bldg,
                sim_bldg,
                var_name,
                f"{mvals['MBE']:.2f}",
                f"{mvals['CVRMSE']:.2f}",
                f"{mvals['NMBE']:.2f}",
                mvals['Pass']
            ])

    # ---------------------------------------------------
    # Check for calibration
    #   We trigger calibration if Pass=False
    # ---------------------------------------------------
    print("\n=== Checking for Calibration Needs ===")
    for (real_bldg, sim_bldg, var_name), mvals in metric_results.items():
        if not mvals['Pass']:
            print(f"[CALIBRATION] RealBldg={real_bldg}, SimBldg={sim_bldg}, Var={var_name}: "
                  f"CV(RMSE)={mvals['CVRMSE']:.2f}% > threshold => Trigger calibration steps...")

    # ---------------------------------------------------
    # Bar chart of CV(RMSE) for each (Real, Sim, Var)
    # ---------------------------------------------------
    bar_chart_metrics_for_triple(metric_results, title="CV(RMSE) Validation (Per Real vs. Sim)")

def bar_chart_metrics_for_triple(metric_dict, title="Validation Metrics"):
    """
    Create a bar chart of CV(RMSE) where each bar is (RealBldg vs. SimBldg, VarName).
    """
    if not metric_dict:
        print("[DEBUG] No metrics to plot - metric_dict is empty.")
        return

    labels = []
    cvrmse_values = []
    pass_status = []

    for (real_bldg, sim_bldg, var_name), mvals in metric_dict.items():
        # Example label: "R0-S3-Heating"
        label = f"R{real_bldg}-S{sim_bldg}-{var_name}"
        labels.append(label)
        cvrmse_values.append(mvals['CVRMSE'])
        pass_status.append(mvals['Pass'])

    x = range(len(labels))

    plt.figure(figsize=(12, 6))
    bars = plt.bar(x, cvrmse_values, alpha=0.7)

    # Color-code pass/fail
    for i, bar in enumerate(bars):
        bar.set_color('green' if pass_status[i] else 'red')

    plt.xticks(list(x), labels, rotation=45, ha='right')
    plt.ylabel("CV(RMSE) (%)")
    plt.title(title)
    if cvrmse_values:
        plt.ylim(0, max(cvrmse_values) * 1.1)
    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    main()

  --- File Contents End ---

  File: metrics.py
  --- File Contents Start ---
# validation/metrics.py
import numpy as np

def mean_bias_error(sim_values, obs_values):
    """
    MBE = ( sum(obs_i - sim_i) / sum(obs_i) ) * 100
    """
    sim = np.array(sim_values, dtype=float)
    obs = np.array(obs_values, dtype=float)
    denominator = np.sum(obs)
    if denominator == 0:
        return float('nan')
    mbe = (np.sum(obs - sim) / denominator) * 100.0
    return mbe

def cv_rmse(sim_values, obs_values):
    """
    CV(RMSE) = ( RMSE / mean(obs) ) * 100
    """
    sim = np.array(sim_values, dtype=float)
    obs = np.array(obs_values, dtype=float)
    obs_mean = np.mean(obs)
    if obs_mean == 0:
        return float('nan')
    mse = np.mean((obs - sim)**2)
    rmse = np.sqrt(mse)
    return (rmse / obs_mean) * 100.0

def nmbe(sim_values, obs_values):
    """
    NMBE = 100 * ( sum(obs_i - sim_i) / (n * mean(obs)) )
    """
    sim = np.array(sim_values, dtype=float)
    obs = np.array(obs_values, dtype=float)
    n = len(sim)
    obs_mean = np.mean(obs)
    if obs_mean == 0:
        return float('nan')
    nmbe_val = 100.0 * (np.sum(obs - sim) / (n * obs_mean))
    return nmbe_val

  --- File Contents End ---

  File: validate_results_custom.py
  --- File Contents Start ---
# validate_results_custom.py

import pandas as pd
from validation.compare_sims_with_measured import load_csv_as_df, align_data_for_variable
from validation.metrics import mean_bias_error, cv_rmse, nmbe
from validation.visualize import (
    plot_time_series_comparison,
    scatter_plot_comparison,
)

def validate_with_ranges(
    real_data_path, 
    sim_data_path, 
    bldg_ranges, 
    threshold_cv_rmse=30.0,
    skip_plots=False
):
    """
    Compare each real building with each sim building in the given range one-by-one,
    computing metrics (MBE, CV(RMSE), NMBE) for each pairing.

    :param skip_plots: If True, do NOT generate any figures (time-series or scatter).
    """
    df_real = pd.read_csv(real_data_path)
    df_sim  = pd.read_csv(sim_data_path)

    # Strip whitespace, if needed, to avoid trailing-space issues
    df_real["VariableName"] = df_real["VariableName"].astype(str).str.strip()
    df_sim["VariableName"]  = df_sim["VariableName"].astype(str).str.strip()

    results = {}

    for real_bldg, sim_bldg_range in bldg_ranges.items():
        # Filter real data for just the real_bldg
        df_real_sub = df_real[df_real["BuildingID"] == real_bldg]
        if df_real_sub.empty:
            print(f"[WARN] No real data for building {real_bldg}")
            continue

        # For each sim building in that range
        for sim_bldg in sim_bldg_range:
            df_sim_sub = df_sim[df_sim["BuildingID"] == sim_bldg]
            if df_sim_sub.empty:
                print(f"[WARN] No sim data for building {sim_bldg}")
                continue

            # For each variable in real data
            for var_name in df_real_sub["VariableName"].unique():
                # Align by passing both real and sim building IDs
                sim_vals, obs_vals, merged_df = align_data_for_variable(
                    df_real_sub, 
                    df_sim_sub,
                    real_bldg,  # real building
                    sim_bldg,   # sim building
                    var_name
                )

                if len(sim_vals) == 0 or len(obs_vals) == 0:
                    continue

                # Compute metrics
                this_mbe = mean_bias_error(sim_vals, obs_vals)
                this_cv  = cv_rmse(sim_vals, obs_vals)
                this_nmbe = nmbe(sim_vals, obs_vals)

                pass_fail = False
                if this_cv is not None and not (this_cv is float('nan')):
                    pass_fail = (this_cv < threshold_cv_rmse)

                # Store metrics in the results dictionary
                results[(real_bldg, sim_bldg, var_name)] = {
                    'MBE': this_mbe,
                    'CVRMSE': this_cv,
                    'NMBE': this_nmbe,
                    'Pass': pass_fail
                }

                # (NEW) Skip plots if requested
                if not skip_plots:
                    label_for_plot = f"{real_bldg}_VS_{sim_bldg}"
                    plot_time_series_comparison(merged_df, label_for_plot, var_name)
                    scatter_plot_comparison(merged_df, label_for_plot, var_name)

    return results

  --- File Contents End ---

  File: visualize.py
  --- File Contents Start ---
# validation/visualize.py
import matplotlib.pyplot as plt

def plot_time_series_comparison(merged_df, building_id, variable_name):
    """
    Creates a simple line plot comparing sim vs. obs over time 
    (e.g., 01-Jan, 02-Jan, etc.).
    merged_df has columns: Date, Value_obs, Value_sim
    """
    if merged_df.empty:
        print(f"[DEBUG] No data to plot for Bldg={building_id}, Var={variable_name}")
        return

    x_vals = merged_df['Date']  # might be strings like '01-Jan'
    obs_vals = merged_df['Value_obs']
    sim_vals = merged_df['Value_sim']

    plt.figure(figsize=(10,6))
    plt.plot(x_vals, obs_vals, 'o-', label='Observed')
    plt.plot(x_vals, sim_vals, 's-', label='Simulated')

    plt.title(f"Building {building_id} - {variable_name}")
    plt.xlabel("Date")
    plt.ylabel("Value")
    plt.legend()
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

def scatter_plot_comparison(merged_df, building_id, variable_name):
    """
    Creates a scatter plot of Observed vs. Simulated for a quick correlation check.
    """
    if merged_df.empty:
        print(f"[DEBUG] No data to plot scatter for Bldg={building_id}, Var={variable_name}")
        return

    obs_vals = merged_df['Value_obs']
    sim_vals = merged_df['Value_sim']

    plt.figure(figsize=(6,6))
    plt.scatter(obs_vals, sim_vals, alpha=0.7)
    # 1:1 line
    mn, mx = min(obs_vals.min(), sim_vals.min()), max(obs_vals.max(), sim_vals.max())
    plt.plot([mn, mx], [mn, mx], color='red', linestyle='--', label='1:1 line')

    plt.title(f"Scatter Comparison: Bldg={building_id}, Var={variable_name}")
    plt.xlabel("Observed")
    plt.ylabel("Simulated")
    plt.legend()
    plt.tight_layout()
    plt.show()

def bar_chart_metrics(metric_dict, title="Validation Metrics"):
    """
    Suppose metric_dict is e.g.:
      {
        (0, 'Cooling'): {'MBE': 2.3, 'CVRMSE': 18.5, 'NMBE': -0.4, 'Pass': True},
        (0, 'Heating'): { ... },
        (1, 'Cooling'): { ... },
        ...
      }
    We'll create a bar chart of CV(RMSE) across all keys.
    """
    import numpy as np

    if not metric_dict:
        print("[DEBUG] No metrics to plot - metric_dict is empty.")
        return

    labels = []
    cvrmse_values = []
    pass_status = []

    for (b_id, var), mvals in metric_dict.items():
        label = f"B{b_id}-{var}"
        labels.append(label)
        cvrmse_values.append(mvals['CVRMSE'])
        pass_status.append(mvals['Pass'])

    x = range(len(labels))

    plt.figure(figsize=(10,5))
    bars = plt.bar(x, cvrmse_values, color='blue', alpha=0.6)

    # Color code pass/fail if you want:
    for i, bar in enumerate(bars):
        if pass_status[i]:
            bar.set_color('green')
        else:
            bar.set_color('red')

    plt.xticks(list(x), labels, rotation=45, ha='right')
    plt.ylabel("CV(RMSE) (%)")
    plt.title(title)

    if cvrmse_values:
        plt.ylim(0, max(cvrmse_values)*1.1)
    plt.tight_layout()
    plt.show()

  --- File Contents End ---

================================================================================

Folder: D:\Documents\E_Plus_2030_py\validation\__pycache__

================================================================================

