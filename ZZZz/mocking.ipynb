{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merged daily mean mocked simulations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock data generated and saved to output/results/merged_daily_mean_mocked.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "input_file = 'output/results/merged_daily_mean.csv'  # Path to your input CSV\n",
    "output_file = 'output/results/merged_daily_mean_mocked.csv'  # Path for the output CSV\n",
    "num_new_buildings = 5  # Number of new BuildingIDs to generate\n",
    "fluctuation_percentage = 0.2  # ±20%\n",
    "\n",
    "# Read the existing CSV\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Ensure 'BuildingID' is numeric\n",
    "# This will convert the column to numeric, setting errors='coerce' will turn non-convertible values to NaN\n",
    "df['BuildingID'] = pd.to_numeric(df['BuildingID'], errors='coerce')\n",
    "\n",
    "# Check for any NaN values in 'BuildingID' after conversion\n",
    "if df['BuildingID'].isnull().any():\n",
    "    raise ValueError(\"Some BuildingID values could not be converted to numbers. Please check your data.\")\n",
    "\n",
    "# If 'BuildingID' should be integer, convert it\n",
    "df['BuildingID'] = df['BuildingID'].astype(int)\n",
    "\n",
    "# Identify existing BuildingIDs\n",
    "existing_buildings = df['BuildingID'].unique()\n",
    "max_building_id = existing_buildings.max()\n",
    "\n",
    "# Generate new BuildingIDs\n",
    "new_building_ids = range(max_building_id + 1, max_building_id + 1 + num_new_buildings)\n",
    "\n",
    "# Identify date columns (assuming they start from the third column)\n",
    "date_columns = df.columns[2:]\n",
    "\n",
    "# Create a list to hold new rows\n",
    "new_rows = []\n",
    "\n",
    "for new_id in new_building_ids:\n",
    "    for _, row in df.iterrows():\n",
    "        new_row = row.copy()\n",
    "        new_row['BuildingID'] = new_id\n",
    "        # Apply ±20% fluctuation to each date column\n",
    "        for date in date_columns:\n",
    "            original_value = row[date]\n",
    "            if pd.isna(original_value):\n",
    "                # If the original value is NaN, keep it as NaN\n",
    "                new_value = original_value\n",
    "            else:\n",
    "                # Generate a random fluctuation factor between -20% and +20%\n",
    "                factor = np.random.uniform(1 - fluctuation_percentage, 1 + fluctuation_percentage)\n",
    "                new_value = original_value * factor\n",
    "            new_row[date] = new_value\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# Create a DataFrame for new rows\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Append the new rows to the original DataFrame\n",
    "combined_df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "# Optionally, sort the DataFrame by BuildingID and VariableName\n",
    "combined_df.sort_values(by=['BuildingID', 'VariableName'], inplace=True)\n",
    "\n",
    "# Save to a new CSV\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Mock data generated and saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock data generated and saved to D:\\Documents\\E_Plus_2030_py\\output\\results\\merged_daily_mean_mocked.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "input_file = r'D:\\Documents\\E_Plus_2030_py\\output\\results\\merged_daily_mean.csv'  # Path to your input CSV\n",
    "output_file = r'D:\\Documents\\E_Plus_2030_py\\output\\results\\merged_daily_mean_mocked.csv'  # Path for the output CSV\n",
    "num_new_buildings = 200  # Number of new BuildingIDs to generate\n",
    "fluctuation_percentage = 0.2  # ±20%\n",
    "\n",
    "# 1. Read the existing CSV\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# FIX: Remove leading/trailing spaces from VariableName\n",
    "# ------------------------------------------------------------------------------\n",
    "df['VariableName'] = df['VariableName'].astype(str).str.strip()\n",
    "\n",
    "# 2. Define a mapping from month abbreviations to numbers\n",
    "month_mapping = {\n",
    "    'Jan': '01',\n",
    "    'Feb': '02',\n",
    "    'Mar': '03',\n",
    "    'Apr': '04',\n",
    "    'May': '05',\n",
    "    'Jun': '06',\n",
    "    'Jul': '07',\n",
    "    'Aug': '08',\n",
    "    'Sep': '09',\n",
    "    'Oct': '10',\n",
    "    'Nov': '11',\n",
    "    'Dec': '12'\n",
    "}\n",
    "\n",
    "# 3. Identify date columns (assuming they start from the third column)\n",
    "date_columns = df.columns[2:]\n",
    "\n",
    "# 4. Function to convert 'DD-MMM' to 'MM/DD'\n",
    "def convert_date_format(date_str):\n",
    "    try:\n",
    "        day, month_abbr = date_str.split('-')\n",
    "        month_num = month_mapping.get(month_abbr, '00')  # Default to '00' if month not found\n",
    "        return f\"{month_num}/{day}\"\n",
    "    except ValueError:\n",
    "        # If the format doesn't match, return the original string\n",
    "        return date_str\n",
    "\n",
    "# 5. Rename the date columns\n",
    "new_date_columns = [convert_date_format(col) for col in date_columns]\n",
    "rename_dict = dict(zip(date_columns, new_date_columns))\n",
    "df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Update date_columns to the new names\n",
    "date_columns = new_date_columns\n",
    "\n",
    "# 6. Ensure 'BuildingID' is numeric\n",
    "df['BuildingID'] = pd.to_numeric(df['BuildingID'], errors='coerce')\n",
    "\n",
    "# 7. Check for any NaN values in 'BuildingID' after conversion\n",
    "if df['BuildingID'].isnull().any():\n",
    "    raise ValueError(\"Some BuildingID values could not be converted to numbers. Please check your data.\")\n",
    "\n",
    "# 8. If 'BuildingID' should be integer, convert it\n",
    "df['BuildingID'] = df['BuildingID'].astype(int)\n",
    "\n",
    "# 9. Identify existing BuildingIDs\n",
    "existing_buildings = df['BuildingID'].unique()\n",
    "max_building_id = existing_buildings.max()\n",
    "\n",
    "# 10. Generate new BuildingIDs\n",
    "new_building_ids = range(max_building_id + 1, max_building_id + 1 + num_new_buildings)\n",
    "\n",
    "# 11. Create a list to hold new rows\n",
    "new_rows = []\n",
    "\n",
    "for new_id in new_building_ids:\n",
    "    for _, row in df.iterrows():\n",
    "        new_row = row.copy()\n",
    "        new_row['BuildingID'] = new_id\n",
    "        # Apply ±20% fluctuation to each date column\n",
    "        for date in date_columns:\n",
    "            original_value = row[date]\n",
    "            if pd.isna(original_value):\n",
    "                # If the original value is NaN, keep it as NaN\n",
    "                new_value = original_value\n",
    "            else:\n",
    "                # Generate a random fluctuation factor between -20% and +20%\n",
    "                factor = np.random.uniform(1 - fluctuation_percentage, 1 + fluctuation_percentage)\n",
    "                new_value = original_value * factor\n",
    "            new_row[date] = new_value\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# 12. Create a DataFrame for new rows\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# 13. Append the new rows to the original DataFrame\n",
    "combined_df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "# 14. Optionally, sort the DataFrame by BuildingID and VariableName\n",
    "combined_df.sort_values(by=['BuildingID', 'VariableName'], inplace=True)\n",
    "\n",
    "# 15. Save to a new CSV\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Mock data generated and saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 200 new sets for each BuildingID. Saved to D:\\Documents\\E_Plus_2030_py\\output\\assigned\\master_parameters_mock.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Input file\n",
    "input_csv = r\"D:\\Documents\\E_Plus_2030_py\\output\\assigned\\master_parameters.csv\" # r'output\\assigned\\master_parameters.csv'\n",
    "# Output file for the new, mocked rows\n",
    "output_csv = r'D:\\Documents\\E_Plus_2030_py\\output\\assigned\\master_parameters_mock.csv'\n",
    "\n",
    "# Number of new “copies” per unique BuildingID\n",
    "N = 200\n",
    "\n",
    "def is_float(val):\n",
    "    \"\"\"Check if a string can be cast to float.\"\"\"\n",
    "    try:\n",
    "        float(val)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Read the original dataset\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# List to accumulate all newly generated rows\n",
    "mocked_rows = []\n",
    "\n",
    "# Get the unique BuildingIDs\n",
    "unique_bldg_ids = df['BuildingID'].unique()\n",
    "\n",
    "for bldg_id in unique_bldg_ids:\n",
    "    # Extract rows for this building ID\n",
    "    subset = df[df['BuildingID'] == bldg_id]\n",
    "\n",
    "    # Generate N new sets of rows for this building\n",
    "    for i in range(1, N+1):\n",
    "        # Define a new building ID\n",
    "        # Option 1: create a string like \"4136730_1\"\n",
    "        # new_bldg_id = f\"{bldg_id}_{i}\"\n",
    "        \n",
    "        # Option 2: just do bldg_id*100 + i (if bldg_id is numeric)\n",
    "        new_bldg_id = bldg_id*100 + i\n",
    "        \n",
    "        for _, row in subset.iterrows():\n",
    "            new_row = row.copy()\n",
    "            \n",
    "            # Assign the new BuildingID\n",
    "            new_row['BuildingID'] = new_bldg_id\n",
    "\n",
    "            # 1) Parse assigned_value, min_value, max_value\n",
    "            assigned_str = str(new_row['assigned_value']).strip()\n",
    "            min_str = str(new_row['min_value']).strip()\n",
    "            max_str = str(new_row['max_value']).strip()\n",
    "\n",
    "            assigned_is_float = is_float(assigned_str)\n",
    "            min_is_float = is_float(min_str)\n",
    "            max_is_float = is_float(max_str)\n",
    "\n",
    "            if assigned_is_float:\n",
    "                assigned_val = float(assigned_str)\n",
    "            else:\n",
    "                assigned_val = assigned_str  # keep as string if not numeric\n",
    "\n",
    "            if min_is_float:\n",
    "                min_val = float(min_str)\n",
    "            else:\n",
    "                min_val = None\n",
    "\n",
    "            if max_is_float:\n",
    "                max_val = float(max_str)\n",
    "            else:\n",
    "                max_val = None\n",
    "\n",
    "            # 2) Check for a valid numeric range\n",
    "            has_valid_range = False\n",
    "            if (min_val is not None and max_val is not None \n",
    "                and min_val < max_val and assigned_is_float):\n",
    "                has_valid_range = True\n",
    "\n",
    "            # 3) Mock the assigned_value\n",
    "            if has_valid_range:\n",
    "                # 60% chance keep same, 40% random in [min_val, max_val]\n",
    "                if np.random.rand() < 0.6:\n",
    "                    new_assigned = assigned_val\n",
    "                else:\n",
    "                    new_assigned = np.random.uniform(min_val, max_val)\n",
    "            else:\n",
    "                # No valid range\n",
    "                if not assigned_is_float:\n",
    "                    # Keep string values as is\n",
    "                    new_assigned = assigned_val\n",
    "                else:\n",
    "                    # assigned_val is numeric\n",
    "                    if assigned_val >= 100:\n",
    "                        # vary by ±100\n",
    "                        offset = np.random.randint(-100, 101)\n",
    "                        new_assigned = assigned_val + offset\n",
    "                    else:\n",
    "                        # vary by ±1\n",
    "                        offset = np.random.uniform(-1, 1)\n",
    "                        new_assigned = assigned_val + offset\n",
    "\n",
    "            # Update new_row\n",
    "            new_row['assigned_value'] = new_assigned\n",
    "\n",
    "            # Accumulate\n",
    "            mocked_rows.append(new_row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "mocked_df = pd.DataFrame(mocked_rows)\n",
    "\n",
    "# If you want to include original data + new data, uncomment the next line:\n",
    "# mocked_df = pd.concat([df, mocked_df], ignore_index=True)\n",
    "\n",
    "# Write out to CSV\n",
    "mocked_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Generated {N} new sets for each BuildingID. Saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock Data Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mimicking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new, mimicked data to: D:\\Documents\\E_Plus_2030_py\\output\\results\\mock_merged_daily_mean.csv\n",
      "   BuildingID                                       VariableName  \\\n",
      "0           0                 Cooling:EnergyTransfer [J](Hourly)   \n",
      "1           0                   Electricity:Facility [J](Hourly)   \n",
      "2           0                 Heating:EnergyTransfer [J](Hourly)   \n",
      "3           0  MYDHW_0_WATERHEATER:Water Heater Heating Energ...   \n",
      "\n",
      "          01/01         01/02         01/03         01/04         01/05  \\\n",
      "0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "1  4.637891e+06  1.826048e+06  4.519129e+06  2.189475e+06  4.587645e+06   \n",
      "2  5.356259e+06  8.549588e+06  8.411575e+06  4.913425e+06  5.444363e+06   \n",
      "3  2.280979e+07  1.698950e+07  4.727667e+07  2.095039e+07  4.712216e+07   \n",
      "\n",
      "          01/06         01/07         01/08  ...         12/22         12/23  \\\n",
      "0  0.000000e+00  0.000000e+00  0.000000e+00  ...  0.000000e+00  0.000000e+00   \n",
      "1  1.695626e+06  4.604700e+06  1.852832e+06  ...  4.658748e+06  4.894739e+06   \n",
      "2  5.218741e+06  6.591549e+06  1.304030e+07  ...  4.581283e+06  5.076982e+06   \n",
      "3  1.811504e+07  4.676428e+07  2.124030e+07  ...  1.756422e+07  1.978314e+07   \n",
      "\n",
      "          12/24         12/25         12/26         12/27         12/28  \\\n",
      "0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "1  4.779677e+06  4.364967e+06  2.131347e+06  1.732280e+06  2.076545e+06   \n",
      "2  1.303547e+07  3.271927e+06  4.213499e+06  8.370931e+06  1.063392e+07   \n",
      "3  2.227975e+07  4.997205e+07  1.851557e+07  5.000334e+07  2.469632e+07   \n",
      "\n",
      "          12/29         12/30         12/31  \n",
      "0  0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "1  4.864098e+06  4.465253e+06  4.743422e+06  \n",
      "2  4.718069e+06  5.877235e+06  1.616891e+07  \n",
      "3  4.807342e+07  2.136653e+07  5.080456e+07  \n",
      "\n",
      "[4 rows x 367 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def mimic_merged_daily_mean(\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    rename_dates: bool = True,\n",
    "    method: str = \"scale\",    # \"scale\" or \"random\"\n",
    "    lower_bound: float = 0.3, # For \"scale\": ±30–50%\n",
    "    upper_bound: float = 0.5,\n",
    "    seed: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads `merged_daily_mean.csv`, creates new data that mimics the original,\n",
    "    optionally renames columns like '01-Jan' -> '01/01',\n",
    "    and saves a new CSV file with the modified values.\n",
    "\n",
    "    :param input_path: Full path to the original merged_daily_mean.csv.\n",
    "    :param output_path: Where the new CSV should be written.\n",
    "    :param rename_dates: Whether to attempt converting 'DD-Mmm' -> 'MM/DD' columns.\n",
    "    :param method: \"scale\" to multiply each numeric cell by a random factor; \n",
    "                   \"random\" to generate random values in original min–max range.\n",
    "    :param lower_bound: Lower bound of the random factor (e.g. 0.3 -> ±30%).\n",
    "    :param upper_bound: Upper bound of the random factor (e.g. 0.5 -> ±50%).\n",
    "    :param seed: Random seed for reproducibility.\n",
    "    :return: The new pandas DataFrame.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 1. Read the original CSV\n",
    "    df_original = pd.read_csv(input_path)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # FIX: Remove leading/trailing spaces from VariableName to avoid mismatches\n",
    "    # --------------------------------------------------------------------------\n",
    "    df_original[\"VariableName\"] = df_original[\"VariableName\"].astype(str).str.strip()\n",
    "\n",
    "    # 2. Make a copy so we don't overwrite the original\n",
    "    df_new = df_original.copy()\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2A. Optionally rename date-like columns from 'DD-Mon' -> 'MM/DD'\n",
    "    # -------------------------------------------------------------------------\n",
    "    if rename_dates:\n",
    "        renamed_cols = {}\n",
    "        for col in df_new.columns:\n",
    "            # Look for 'DD-Mmm' format\n",
    "            match = re.match(r\"^(\\d{2})-(\\w{3})$\", col)\n",
    "            if match:\n",
    "                day_str, month_str = match.groups()\n",
    "                try:\n",
    "                    dt = datetime.strptime(f\"{day_str}-{month_str}-2025\", \"%d-%b-%Y\")\n",
    "                    new_col_name = dt.strftime(\"%m/%d\")  # e.g. 01-Jan -> 01/01\n",
    "                    renamed_cols[col] = new_col_name\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "        # Actually rename the columns in df_new\n",
    "        df_new.rename(columns=renamed_cols, inplace=True)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3. Mimic numeric data\n",
    "    # -------------------------------------------------------------------------\n",
    "    skip_cols = [\"BuildingID\", \"VariableName\"]\n",
    "    cols_to_modify = [\n",
    "        c for c in df_new.columns\n",
    "        if c not in skip_cols\n",
    "    ]\n",
    "\n",
    "    for col in cols_to_modify:\n",
    "        # Convert to numeric (coercing errors to NaN, though hopefully none)\n",
    "        df_new[col] = pd.to_numeric(df_new[col], errors=\"coerce\")\n",
    "\n",
    "        # Skip columns that are entirely NaN or non-numeric\n",
    "        if df_new[col].notna().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        # Two approaches:\n",
    "        # ---------------------------------------------------\n",
    "        # A) Scale the existing data by a random factor: ±(30%–50%).\n",
    "        # ---------------------------------------------------\n",
    "        if method == \"scale\":\n",
    "            # +1 or -1 direction\n",
    "            scale_direction = np.random.choice([-1, 1], size=len(df_new))\n",
    "            # random magnitude in [lower_bound..upper_bound]\n",
    "            scale_pct = np.random.uniform(lower_bound, upper_bound, size=len(df_new))\n",
    "            factor = 1 + (scale_direction * scale_pct)\n",
    "            df_new[col] = df_new[col] * factor\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # B) Generate brand-new random data in [min..max] range\n",
    "        # ---------------------------------------------------\n",
    "        elif method == \"random\":\n",
    "            old_min, old_max = df_new[col].min(), df_new[col].max()\n",
    "            if old_min == old_max:\n",
    "                # If there's no range, give a small offset\n",
    "                old_min -= 1.0\n",
    "                old_max += 1.0\n",
    "            df_new[col] = np.random.uniform(old_min, old_max, size=len(df_new))\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown method. Choose 'scale' or 'random'.\")\n",
    "\n",
    "    # 4. Save the result\n",
    "    df_new.to_csv(output_path, index=False)\n",
    "    return df_new\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    input_file = r\"D:\\Documents\\E_Plus_2030_py\\output\\results\\merged_daily_mean.csv\"\n",
    "    output_file = r\"D:\\Documents\\E_Plus_2030_py\\output\\results\\mock_merged_daily_mean.csv\"\n",
    "\n",
    "    df_mocked = mimic_merged_daily_mean(\n",
    "        input_path=input_file,\n",
    "        output_path=output_file,\n",
    "        rename_dates=True,         # Will rename '01-Jan' -> '01/01'\n",
    "        method=\"scale\",            # or \"random\"\n",
    "        lower_bound=0.3,\n",
    "        upper_bound=0.5,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    print(\"Saved new, mimicked data to:\", output_file)\n",
    "    print(df_mocked.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDsaie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
